################################################################################
# training parameters
################################################################################
train:
  loss: "xentropy"       # must be either xentropy or iou
  max_epochs: 100
  lr: 0.05 #0.01              # sgd learning rate
  wup_epochs: 1          # warmup during first XX epochs (can be float)
  momentum: 0.9          # sgd momentum
  lr_decay: 0.99         # learning rate decay per epoch after initial cycle (from min lr)
  w_decay: 0.0001         # weight decay
  batch_size: 20         # 12 batch size
  report_batch: 1        # every x batches, report loss
  report_epoch: 1        # every x epochs, report validation set
  epsilon_w: 1.02      # class weight w = 1 / (content + epsilon_w)
  save_summary: True    # Summary of weight histograms for tensorboard
  save_scans: True       # False doesn't save anything, True saves some 
                         # sample images (one per batch of the last calculated batch)
                         # in log folder
  show_scans: False      # show scans during training
  workers: 12            # number of threads to get data

################################################################################
# Early stopping parameters
################################################################################
early_stopping:
  use: True
  params:
    type: "iou" # one of [iou, loss]
    patience: 15
    delta: 0.001
    verbose: True

################################################################################
# Data augmentation
################################################################################
data_augmentation:
  use: True
  params:
    height_change:
      use: False
      params:
        max_height_diff: 3
        max_angle_diff: 4
        probability: 0.5
    flip:
      use: True
      params:
        probability: 0.5
    translate:
      use: False
      params:
        augment: False
        x: 3
        z: 3
        angle: 0.1

weighted_sampling:
  use: False
  weights:
    0: 0
    1: 0
    10: 0.006786154069931918
    30: 0.0003113786738286537
    40: 0.008376384661172928
    49: 0.8500148144232017
    52: 0.0005695600218644999
    70: 0.12574824458364672

loss_weights:
  frequency: False
  logbased: True
  noweights: False


################################################################################
# backbone parameters
################################################################################
backbone:
  name: "darknet"  # ['squeezeseg', 'squeezesegV2', 'darknet']
  input_depth:
    range: True
    xyz: True
    remission: True
  dropout: 0.01
  bn_d: 0.01
  OS: 32 # output stride (only horizontally)
  train: True # train backbone?
  extra:
    layers: 53

################################################################################
# decoder parameters
################################################################################
decoder:
  name: "darknet"
  dropout: 0.01
  bn_d: 0.01
  train: True # train decoder?
  extra: False # nothing to add for this decoder, otherwise this is a dict

################################################################################
# classification head parameters
################################################################################
head:
  name: "segmentation"
  train: True
  dropout: 0.01

################################################################################
# postproc parameters
################################################################################
post:
  CRF: 
    use: False
    train: True
    params: False
  KNN:
    use: True
    params:
      knn: 5
      search: 5
      sigma: 1.0 
      cutoff: 1.0

################################################################################
# classification head parameters
################################################################################
# dataset (to find parser)
dataset:
  labels: "kitti" # This decides the parser, 'kitti' since UAV data uses the same parser as Semantickitti 
  scans: "kitti"  # This decides the parser, 'kitti' since UAV data uses the same parser as SemanticKitti 
  max_points: 20000 # max of any scan in dataset
  sensor:
    name: "UAV"  # VLP-16 
    type: "spherical" # projective
    fov_up: 15
    fov_down: -15
    img_prop:
      width: 1024
      height: 16 
    img_means: #range,x,y,z,signal
      - 16.9885
      - 11.5028
      - -0.0024
      - -0.1778
      - 0.0655
    img_stds: #range,x,y,z,signal
      - 7.3313959
      - 3.20026766
      - 13.8132747
      - 2.99412273
      - 0.03025917

