################################################################################
# training parameters
################################################################################
train:
  loss: "xentropy"       # must be either xentropy or iou
  max_epochs: 150 #150
  lr: 0.01               # sgd learning rate
  wup_epochs: 1          # warmup during first XX epochs (can be float)
  momentum: 0.9          # sgd momentum
  lr_decay: 0.995        # learning rate decay per epoch after initial cycle (from min lr)
  w_decay: 0.0001        # weight decay
  batch_size: 20         # batch size, default 2
  report_batch: 1        # every x batches, report loss
  report_epoch: 1        # every x epochs, report validation set
  epsilon_w: 1.02       # class weight w = 1 / (content + epsilon_w)
  save_summary: False    # Summary of weight histograms for tensorboard
  save_scans: True       # False doesn't save anything, True saves some 
                         # sample images (one per batch of the last calculated batch)
                         # in log folder
  show_scans: False      # show scans during training
  workers: 12            # number of threads to get data

################################################################################
# Early stopping parameters
################################################################################
early_stopping:
  use: True
  params:
    type: "iou"
    patience: 20
    delta: 0.001
    verbose: True

################################################################################
# Data augmentation, THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=11 : invalid argument
################################################################################
data_augmentation:
  use: True
  params:
    height_change:
      use: False
      params:
        max_height_diff: 6
        max_angle_diff: 12
        probability: 0.5
    flip:
      use: True
      params:
        probability: 0.5
    translate:
      use: False
      params:
        augment: False
        x: 3
        z: 3
        angle: 0.1


weighted_sampling:
  use: False
  weights:
    0: 0
    1: 0
    10: 0.0070165179984583645
    30: 0.00030689974629202673
    49: 0.8505500587760465
    52: 0.0006100544215680954
    70: 0.1330349616300808

loss_weights:
  frequency: False
  logbased: True
  noweights: False

################################################################################
# backbone parameters
################################################################################
backbone:
  name: "darknet"  # ['squeezeseg', 'squeezesegV2', 'darknet']
  input_depth:
    range: True
    xyz: True
    remission: True
  dropout: 0.01
  bn_d: 0.01
  OS: 32 # output stride (only horizontally)
  train: True # train backbone?
  extra:
    layers: 21

################################################################################
# decoder parameters
################################################################################
decoder:
  name: "darknet"
  dropout: 0.01
  bn_d: 0.01
  train: True # train decoder?
  extra: False # nothing to add for this decoder, otherwise this is a dict

################################################################################
# classification head parameters
################################################################################
head:
  name: "segmentation"
  train: True
  dropout: 0.01

################################################################################
# postproc parameters
################################################################################
post:
  CRF: 
    use: False
    train: True
    params: False # this should be a dict when in use
  KNN:
    use: True
    params:
      knn: 5
      search: 5
      sigma: 1.0 
      cutoff: 1.0

################################################################################
# classification head parameters
################################################################################
# dataset (to find parser)
dataset:
  labels: "kitti"
  scans: "kitti"
  max_points: 20000 # max of any scan in dataset
  sensor:
    name: "HDL64"
    type: "spherical" # projective
    fov_up: 3
    fov_down: -25 
    img_prop:
      width: 1024
      height: 16 #64
    img_means: #range,x,y,z,signal
      - 16.08043036
      - 10.81145084
      - -0.09983386
      - 2.89174747
      - 0.28931619
    img_stds: #range,x,y,z,signal
      - 6.95668728
      - 3.8981811
      - 9.47398691
      - 8.76149847
      - 0.14833901
